{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opt4ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda, Pad\n",
    "from torchmetrics import F1Score\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "from collections import Counter\n",
    "import random\n",
    "# Custom libraries\n",
    "from plot_helpers import *\n",
    "from image_processing_helpers import *\n",
    "from k_means import *\n",
    "import custom_optimizers as opt\n",
    "# Allow autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18d27d0c430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 2022\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"data/fashion_mnist/fashion-mnist_train.csv\")\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = training_data.groupby(\"label\").indices\n",
    "validation_idx = np.empty(0)\n",
    "for label, idx in label_idx.items():\n",
    "    random_sampling = np.random.choice(idx,idx.shape[0]//10,replace=False)\n",
    "    validation_idx = np.concatenate([validation_idx,random_sampling],axis=0)\n",
    "training_idx = [i for i in training_data.index if i not in validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_set = training_data.iloc[training_idx]\n",
    "new_validation_set = training_data.iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_set.to_csv(\"data/fashion_mnist/fashion-mnist_new_train.csv\",index=False)\n",
    "new_validation_set.to_csv(\"data/fashion_mnist/fashion-mnist_new_validation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fashion_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None):\n",
    "        data = pd.read_csv(data_path)\n",
    "        self.labels_df = data[\"label\"]\n",
    "        self.img_labels = data[\"label\"].to_list()\n",
    "        self.images = [(row.to_numpy(dtype=np.float32)/255).reshape((28,28))  \n",
    "                for idx,row in data[data.columns[1:]].iterrows()]\n",
    "        self.label_mapping = {0:\"T-shirt/top\", 1:\"Trouser\",\n",
    "                 2:\"Pullover\", 3:\"Dress\", 4:\"Coat\",\n",
    "                 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\",\n",
    "                 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        #image = Pad(2)(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Fashion_Dataset(\"data/fashion_mnist/fashion-mnist_new_train.csv\",transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
    "test_dataset = Fashion_Dataset(\"data/fashion_mnist/fashion-mnist_test.csv\",transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
    "validation_dataset = Fashion_Dataset(\"data/fashion_mnist/fashion-mnist_new_validation.csv\",transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=g)\n",
    "test_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=g)\n",
    "validation_dataloader = DataLoader(validation_dataset,batch_size=batch_size,shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4096, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([4096, 10])\n",
      "Labels: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:]\n",
    "label = train_labels[0]\n",
    "show_images([img])\n",
    "print(f\"Labels: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_hist = train_dataset.labels_df.value_counts().to_dict()\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "labels_names = [train_dataset.label_mapping[i] for i in labels_hist.keys()]\n",
    "ax.bar(labels_names,labels_hist.values())\n",
    "ax.set_title(\"Training Set Class Distribution \");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=1600, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(5*5*64, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterium and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = opt.SGDOptimizer(model.parameters(),lr=1,momentum=0.9)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.3,momentum=0.9)\n",
    "#optimizer= opt.MomentumSGDOptimizer(model.parameters(), lr=1, rho=0.9)\n",
    "f1 = F1Score(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, truth_label = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == truth_label).sum().item()\n",
    "    return 100*correct/total\n",
    "\n",
    "def validation_metrics(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        pred_buffer = torch.empty(0).to(device)\n",
    "        label_buffer = torch.empty(0).to(device)\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, truth_label = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == truth_label).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            pred_buffer = torch.cat([pred_buffer,outputs],dim=0)\n",
    "            label_buffer = torch.cat([label_buffer,labels],dim=0)\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_f1 = f1(pred_buffer.cpu(),label_buffer.int().cpu()).item()\n",
    "    val_acc = 100*correct/total\n",
    "    return val_loss, val_f1, val_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_12252\\571705098.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\t Iteration 14\t Train_Loss: 2.30169\t Train_F1_Score: 0.00000\t Train_Accuracy: 17.14444\t Val_Loss: 2.29986\t Val_F1_Score: 0.00000\t Val_Accuracy: 17.40000\n",
      "Epoch 2\t Iteration 14\t Train_Loss: 2.29489\t Train_F1_Score: 0.00000\t Train_Accuracy: 19.52037\t Val_Loss: 2.28368\t Val_F1_Score: 0.00000\t Val_Accuracy: 19.63333\n",
      "Epoch 3\t Iteration 14\t Train_Loss: 2.23849\t Train_F1_Score: 0.12725\t Train_Accuracy: 28.76296\t Val_Loss: 2.16955\t Val_F1_Score: 0.32447\t Val_Accuracy: 28.58333\n",
      "Epoch 4\t Iteration 14\t Train_Loss: 2.08956\t Train_F1_Score: 0.37150\t Train_Accuracy: 47.26481\t Val_Loss: 2.01205\t Val_F1_Score: 0.46644\t Val_Accuracy: 46.18333\n",
      "Epoch 5\t Iteration 14\t Train_Loss: 1.99082\t Train_F1_Score: 0.47216\t Train_Accuracy: 48.30370\t Val_Loss: 1.98779\t Val_F1_Score: 0.47588\t Val_Accuracy: 47.51667\n",
      "Epoch 6\t Iteration 14\t Train_Loss: 1.96101\t Train_F1_Score: 0.49896\t Train_Accuracy: 55.45926\t Val_Loss: 1.90975\t Val_F1_Score: 0.55064\t Val_Accuracy: 54.45000\n",
      "Epoch 7\t Iteration 14\t Train_Loss: 1.87307\t Train_F1_Score: 0.59129\t Train_Accuracy: 61.30370\t Val_Loss: 1.85230\t Val_F1_Score: 0.61158\t Val_Accuracy: 61.05000\n",
      "Epoch 8\t Iteration 14\t Train_Loss: 1.82944\t Train_F1_Score: 0.63587\t Train_Accuracy: 63.24444\t Val_Loss: 1.83902\t Val_F1_Score: 0.63006\t Val_Accuracy: 62.51667\n",
      "Epoch 9\t Iteration 14\t Train_Loss: 1.81923\t Train_F1_Score: 0.64491\t Train_Accuracy: 64.92407\t Val_Loss: 1.81981\t Val_F1_Score: 0.64517\t Val_Accuracy: 64.08333\n",
      "Epoch 10\t Iteration 14\t Train_Loss: 1.80463\t Train_F1_Score: 0.66054\t Train_Accuracy: 66.32222\t Val_Loss: 1.80523\t Val_F1_Score: 0.65770\t Val_Accuracy: 65.38333\n",
      "Epoch 11\t Iteration 14\t Train_Loss: 1.79577\t Train_F1_Score: 0.66732\t Train_Accuracy: 63.78519\t Val_Loss: 1.82150\t Val_F1_Score: 0.63893\t Val_Accuracy: 63.53333\n",
      "Epoch 12\t Iteration 14\t Train_Loss: 1.80075\t Train_F1_Score: 0.66331\t Train_Accuracy: 66.93148\t Val_Loss: 1.79786\t Val_F1_Score: 0.66801\t Val_Accuracy: 66.43333\n",
      "Epoch 13\t Iteration 14\t Train_Loss: 1.78673\t Train_F1_Score: 0.67968\t Train_Accuracy: 67.84630\t Val_Loss: 1.78982\t Val_F1_Score: 0.67396\t Val_Accuracy: 66.95000\n",
      "Epoch 14\t Iteration 14\t Train_Loss: 1.78128\t Train_F1_Score: 0.68524\t Train_Accuracy: 67.90741\t Val_Loss: 1.79379\t Val_F1_Score: 0.67638\t Val_Accuracy: 67.10000\n",
      "Epoch 15\t Iteration 14\t Train_Loss: 1.77614\t Train_F1_Score: 0.69000\t Train_Accuracy: 68.29259\t Val_Loss: 1.78684\t Val_F1_Score: 0.67884\t Val_Accuracy: 67.41667\n",
      "Epoch 16\t Iteration 14\t Train_Loss: 1.77219\t Train_F1_Score: 0.69418\t Train_Accuracy: 68.71111\t Val_Loss: 1.77897\t Val_F1_Score: 0.68494\t Val_Accuracy: 67.93333\n",
      "Epoch 17\t Iteration 14\t Train_Loss: 1.76821\t Train_F1_Score: 0.69947\t Train_Accuracy: 69.50370\t Val_Loss: 1.76882\t Val_F1_Score: 0.69537\t Val_Accuracy: 69.05000\n",
      "Epoch 18\t Iteration 14\t Train_Loss: 1.75065\t Train_F1_Score: 0.71696\t Train_Accuracy: 77.91296\t Val_Loss: 1.70408\t Val_F1_Score: 0.77302\t Val_Accuracy: 77.21667\n",
      "Epoch 19\t Iteration 14\t Train_Loss: 1.68999\t Train_F1_Score: 0.78018\t Train_Accuracy: 78.41296\t Val_Loss: 1.68782\t Val_F1_Score: 0.77895\t Val_Accuracy: 77.83333\n",
      "Epoch 20\t Iteration 14\t Train_Loss: 1.67677\t Train_F1_Score: 0.78730\t Train_Accuracy: 79.09630\t Val_Loss: 1.68237\t Val_F1_Score: 0.78213\t Val_Accuracy: 78.15000\n",
      "Epoch 21\t Iteration 14\t Train_Loss: 1.67166\t Train_F1_Score: 0.79276\t Train_Accuracy: 79.69630\t Val_Loss: 1.67373\t Val_F1_Score: 0.78864\t Val_Accuracy: 78.88333\n",
      "Epoch 22\t Iteration 14\t Train_Loss: 1.66540\t Train_F1_Score: 0.79883\t Train_Accuracy: 79.64259\t Val_Loss: 1.67533\t Val_F1_Score: 0.78730\t Val_Accuracy: 78.66667\n",
      "Epoch 23\t Iteration 14\t Train_Loss: 1.66359\t Train_F1_Score: 0.80281\t Train_Accuracy: 80.07222\t Val_Loss: 1.66846\t Val_F1_Score: 0.79652\t Val_Accuracy: 79.61667\n",
      "Epoch 24\t Iteration 14\t Train_Loss: 1.65896\t Train_F1_Score: 0.80661\t Train_Accuracy: 80.86667\t Val_Loss: 1.66058\t Val_F1_Score: 0.80284\t Val_Accuracy: 80.26667\n",
      "Epoch 25\t Iteration 14\t Train_Loss: 1.65598\t Train_F1_Score: 0.81056\t Train_Accuracy: 78.05741\t Val_Loss: 1.68891\t Val_F1_Score: 0.77440\t Val_Accuracy: 77.33333\n",
      "Epoch 26\t Iteration 14\t Train_Loss: 1.66012\t Train_F1_Score: 0.80309\t Train_Accuracy: 81.17407\t Val_Loss: 1.66285\t Val_F1_Score: 0.80267\t Val_Accuracy: 80.18333\n",
      "Epoch 27\t Iteration 14\t Train_Loss: 1.65168\t Train_F1_Score: 0.81449\t Train_Accuracy: 81.33333\t Val_Loss: 1.65661\t Val_F1_Score: 0.80715\t Val_Accuracy: 80.61667\n",
      "Epoch 28\t Iteration 14\t Train_Loss: 1.65065\t Train_F1_Score: 0.81522\t Train_Accuracy: 80.94074\t Val_Loss: 1.66035\t Val_F1_Score: 0.80040\t Val_Accuracy: 80.05000\n",
      "Epoch 29\t Iteration 14\t Train_Loss: 1.64812\t Train_F1_Score: 0.81575\t Train_Accuracy: 81.51296\t Val_Loss: 1.65364\t Val_F1_Score: 0.80805\t Val_Accuracy: 80.78333\n",
      "Epoch 30\t Iteration 14\t Train_Loss: 1.64564\t Train_F1_Score: 0.81893\t Train_Accuracy: 81.92037\t Val_Loss: 1.64710\t Val_F1_Score: 0.81363\t Val_Accuracy: 81.30000\n",
      "Epoch 31\t Iteration 14\t Train_Loss: 1.64672\t Train_F1_Score: 0.81728\t Train_Accuracy: 81.94630\t Val_Loss: 1.65123\t Val_F1_Score: 0.81173\t Val_Accuracy: 81.10000\n",
      "Epoch 32\t Iteration 14\t Train_Loss: 1.64505\t Train_F1_Score: 0.81914\t Train_Accuracy: 82.13519\t Val_Loss: 1.64918\t Val_F1_Score: 0.81146\t Val_Accuracy: 81.05000\n",
      "Epoch 33\t Iteration 14\t Train_Loss: 1.64206\t Train_F1_Score: 0.82179\t Train_Accuracy: 82.09630\t Val_Loss: 1.64737\t Val_F1_Score: 0.81352\t Val_Accuracy: 81.33333\n",
      "Epoch 34\t Iteration 14\t Train_Loss: 1.64127\t Train_F1_Score: 0.82261\t Train_Accuracy: 82.13519\t Val_Loss: 1.64642\t Val_F1_Score: 0.81676\t Val_Accuracy: 81.68333\n",
      "Epoch 35\t Iteration 14\t Train_Loss: 1.63978\t Train_F1_Score: 0.82375\t Train_Accuracy: 82.30185\t Val_Loss: 1.64808\t Val_F1_Score: 0.81516\t Val_Accuracy: 81.40000\n",
      "Epoch 36\t Iteration 14\t Train_Loss: 1.63911\t Train_F1_Score: 0.82485\t Train_Accuracy: 82.16296\t Val_Loss: 1.64579\t Val_F1_Score: 0.81907\t Val_Accuracy: 81.85000\n",
      "Epoch 37\t Iteration 14\t Train_Loss: 1.64193\t Train_F1_Score: 0.82128\t Train_Accuracy: 81.59444\t Val_Loss: 1.65348\t Val_F1_Score: 0.81035\t Val_Accuracy: 80.98333\n",
      "Epoch 38\t Iteration 14\t Train_Loss: 1.64039\t Train_F1_Score: 0.82262\t Train_Accuracy: 82.15741\t Val_Loss: 1.64903\t Val_F1_Score: 0.81603\t Val_Accuracy: 81.55000\n",
      "Epoch 39\t Iteration 14\t Train_Loss: 1.63690\t Train_F1_Score: 0.82700\t Train_Accuracy: 82.93889\t Val_Loss: 1.64380\t Val_F1_Score: 0.82242\t Val_Accuracy: 82.20000\n",
      "Epoch 40\t Iteration 14\t Train_Loss: 1.63467\t Train_F1_Score: 0.82899\t Train_Accuracy: 82.95926\t Val_Loss: 1.63849\t Val_F1_Score: 0.82418\t Val_Accuracy: 82.33333\n",
      "Epoch 41\t Iteration 14\t Train_Loss: 1.63419\t Train_F1_Score: 0.82893\t Train_Accuracy: 82.52778\t Val_Loss: 1.64423\t Val_F1_Score: 0.81946\t Val_Accuracy: 81.95000\n",
      "Epoch 42\t Iteration 14\t Train_Loss: 1.63748\t Train_F1_Score: 0.82490\t Train_Accuracy: 82.43889\t Val_Loss: 1.64369\t Val_F1_Score: 0.81782\t Val_Accuracy: 81.71667\n",
      "Epoch 43\t Iteration 14\t Train_Loss: 1.63344\t Train_F1_Score: 0.82911\t Train_Accuracy: 83.15370\t Val_Loss: 1.63571\t Val_F1_Score: 0.82703\t Val_Accuracy: 82.66667\n",
      "Epoch 44\t Iteration 14\t Train_Loss: 1.63000\t Train_F1_Score: 0.83181\t Train_Accuracy: 83.02963\t Val_Loss: 1.63608\t Val_F1_Score: 0.82637\t Val_Accuracy: 82.56667\n",
      "Epoch 45\t Iteration 14\t Train_Loss: 1.63084\t Train_F1_Score: 0.83215\t Train_Accuracy: 83.30926\t Val_Loss: 1.63399\t Val_F1_Score: 0.82837\t Val_Accuracy: 82.80000\n",
      "Epoch 46\t Iteration 14\t Train_Loss: 1.62962\t Train_F1_Score: 0.83446\t Train_Accuracy: 83.54074\t Val_Loss: 1.63586\t Val_F1_Score: 0.82922\t Val_Accuracy: 82.86667\n",
      "Epoch 47\t Iteration 14\t Train_Loss: 1.62905\t Train_F1_Score: 0.83411\t Train_Accuracy: 83.39815\t Val_Loss: 1.63528\t Val_F1_Score: 0.82621\t Val_Accuracy: 82.53333\n",
      "Epoch 48\t Iteration 14\t Train_Loss: 1.62919\t Train_F1_Score: 0.83388\t Train_Accuracy: 83.60370\t Val_Loss: 1.63735\t Val_F1_Score: 0.83001\t Val_Accuracy: 82.95000\n",
      "Epoch 49\t Iteration 14\t Train_Loss: 1.62795\t Train_F1_Score: 0.83504\t Train_Accuracy: 82.70185\t Val_Loss: 1.64280\t Val_F1_Score: 0.81855\t Val_Accuracy: 81.76667\n",
      "Epoch 50\t Iteration 14\t Train_Loss: 1.62954\t Train_F1_Score: 0.83313\t Train_Accuracy: 82.86481\t Val_Loss: 1.63630\t Val_F1_Score: 0.82278\t Val_Accuracy: 82.26667\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 100\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pred_buffer = torch.empty(0).to(device)\n",
    "    label_buffer = torch.empty(0).to(device)\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save statistics\n",
    "        running_loss += loss.item()\n",
    "        pred_buffer = torch.cat([pred_buffer,outputs],dim=0)\n",
    "        label_buffer = torch.cat([label_buffer,labels],dim=0)\n",
    "        # Print statistics\n",
    "        if i == len(train_dataloader)-1:    # print at the end of the epoch\n",
    "            f1_score = f1(pred_buffer.cpu(),label_buffer.int().cpu())\n",
    "            accuracy = compute_accuracy(train_dataloader)\n",
    "            val_loss, val_f1_score, val_accuracy = validation_metrics(validation_dataloader)\n",
    "            print(f'Epoch {epoch + 1}\\t Iteration {i + 1}\\t Train_Loss: {running_loss / len(train_dataloader):.5f}\\t ',end=\"\")\n",
    "            print(f\"Train_F1_Score: {f1_score:.5f}\\t Train_Accuracy: {accuracy:.5f}\\t \",end=\"\")\n",
    "            print(f\"Val_Loss: {val_loss:.5f}\\t Val_F1_Score: {val_f1_score:.5f}\\t Val_Accuracy: {val_accuracy:.5f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_12252\\571705098.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.86481 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, truth_label = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == truth_label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.5f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    files = [cv2.imread(join(folder_path,f)) for f in listdir(folder_path) \n",
    "             if os.path.isfile(join(folder_path,f))]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_im = load_data(\"data/chest_xray/train/PNEUMONIA\")\n",
    "healthy_im = load_data(\"data/chest_xray/train/NORMAL/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "show_images([disease_im[i],healthy_im[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size_histogram(disease_im,\"Histogram of image sizes for the tumor set\")\n",
    "plot_size_histogram(healthy_im,\"Histogram of image sizes for the healthy set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_tumor_im = [cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in tumor_im]\n",
    "gray_healthy_im = [cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in healthy_im]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_tumor_im = [kmean_compression(im,k=2) for im in gray_tumor_im]\n",
    "compressed_healthy_im = [kmean_compression(im,k=2) for im in gray_healthy_im]\n",
    "show_images([compressed_tumor_im[i],compressed_healthy_im[i]],\"Example of K-Mean compression on our dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain(image):\n",
    "    # Convert images to gray scale\n",
    "    gray_im = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Compress/Segment the image using k-means\n",
    "    compressed_im = kmean_compression(gray_im,k=2)\n",
    "    # Remove artifacts\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(17,17))\n",
    "    morphed_im = cv2.morphologyEx(compressed_im, cv2.MORPH_OPEN, kernel)\n",
    "    # Masks the brain\n",
    "    mask_im = np.zeros(morphed_im.shape)\n",
    "    mask_im[morphed_im > morphed_im.mean()] = 1\n",
    "    #plt.imshow(mask_im)\n",
    "    plt.imshow(compressed_im)\n",
    "    corners = retrieve_corners_opt(mask_im)\n",
    "    brain_segmentation = extract_brain(image,corners)\n",
    "    return brain_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crop_brain(tumor_im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,10,kernel_size=(3,3),padding=1),\n",
    "            nn.Conv2d(10,10,kernel_size=(3,3),padding=1),\n",
    "            nn.Conv2d(10,10,kernel_size=(3,3),padding=1)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
