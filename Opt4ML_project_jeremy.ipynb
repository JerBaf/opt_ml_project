{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opt4ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda, Pad\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "from collections import Counter\n",
    "import random\n",
    "# Custom libraries\n",
    "from plot_helpers import *\n",
    "from image_processing_helpers import *\n",
    "from k_means import *\n",
    "import custom_optimizers as opt\n",
    "# Allow autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fashion_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None):\n",
    "        data = pd.read_csv(data_path)\n",
    "        self.labels_df = data[\"label\"]\n",
    "        self.img_labels = data[\"label\"].to_list()\n",
    "        self.images = [(row.to_numpy(dtype=np.float32)/255).reshape((28,28))  \n",
    "                for idx,row in data[data.columns[1:]].iterrows()]\n",
    "        self.label_mapping = {0:\"T-shirt/top\", 1:\"Trouser\",\n",
    "                 2:\"Pullover\", 3:\"Dress\", 4:\"Coat\",\n",
    "                 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\",\n",
    "                 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        image = Pad(2)(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Fashion_Dataset(\"data/fashion_mnist/fashion-mnist_train.csv\",transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
    "test_dataset = Fashion_Dataset(\"data/fashion_mnist/fashion-mnist_test.csv\",transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=4096,shuffle=True)\n",
    "test_dataloader = DataLoader(train_dataset,batch_size=4096,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4096, 1, 32, 32])\n",
      "Labels batch shape: torch.Size([4096, 10])\n",
      "Labels: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0,0,:,:]\n",
    "label = train_labels[0]\n",
    "show_images([img])\n",
    "print(f\"Labels: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_hist = train_dataset.labels_df.value_counts().to_dict()\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "labels_names = [train_dataset.label_mapping[i] for i in labels_hist.keys()]\n",
    "ax.bar(labels_names,labels_hist.values())\n",
    "ax.set_title(\"Class Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=8192, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size=3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16*16*32, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterium and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = opt.SGDOptimizer(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_8620\\4106858249.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.298\n",
      "[1,     4] loss: 2.270\n",
      "[1,     6] loss: 2.228\n",
      "[1,     8] loss: 2.181\n",
      "[1,    10] loss: 2.139\n",
      "[1,    12] loss: 2.106\n",
      "[1,    14] loss: 2.072\n",
      "[2,     2] loss: 2.038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opt_ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opt_ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opt_ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opt_ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mFashion_Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     22\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform:\n\u001b[1;32m---> 24\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m image \u001b[38;5;241m=\u001b[39m Pad(\u001b[38;5;241m2\u001b[39m)(image)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opt_ml\\lib\\site-packages\\torchvision\\transforms\\transforms.py:437\u001b[0m, in \u001b[0;36mLambda.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Fashion_Dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/fashion_mnist/fashion-mnist_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[1;32m----> 2\u001b[0m     target_transform\u001b[38;5;241m=\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m y: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Fashion_Dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/fashion_mnist/fashion-mnist_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[0;32m      4\u001b[0m     target_transform\u001b[38;5;241m=\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m y: torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(y), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epoch = 10\n",
    "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, truth_label = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == truth_label).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    files = [cv2.imread(join(folder_path,f)) for f in listdir(folder_path) \n",
    "             if os.path.isfile(join(folder_path,f))]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_im = load_data(\"data/chest_xray/train/PNEUMONIA\")\n",
    "healthy_im = load_data(\"data/chest_xray/train/NORMAL/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "show_images([disease_im[i],healthy_im[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size_histogram(disease_im,\"Histogram of image sizes for the tumor set\")\n",
    "plot_size_histogram(healthy_im,\"Histogram of image sizes for the healthy set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_tumor_im = [cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in tumor_im]\n",
    "gray_healthy_im = [cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in healthy_im]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_tumor_im = [kmean_compression(im,k=2) for im in gray_tumor_im]\n",
    "compressed_healthy_im = [kmean_compression(im,k=2) for im in gray_healthy_im]\n",
    "show_images([compressed_tumor_im[i],compressed_healthy_im[i]],\"Example of K-Mean compression on our dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain(image):\n",
    "    # Convert images to gray scale\n",
    "    gray_im = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Compress/Segment the image using k-means\n",
    "    compressed_im = kmean_compression(gray_im,k=2)\n",
    "    # Remove artifacts\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(17,17))\n",
    "    morphed_im = cv2.morphologyEx(compressed_im, cv2.MORPH_OPEN, kernel)\n",
    "    # Masks the brain\n",
    "    mask_im = np.zeros(morphed_im.shape)\n",
    "    mask_im[morphed_im > morphed_im.mean()] = 1\n",
    "    #plt.imshow(mask_im)\n",
    "    plt.imshow(compressed_im)\n",
    "    corners = retrieve_corners_opt(mask_im)\n",
    "    brain_segmentation = extract_brain(image,corners)\n",
    "    return brain_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = crop_brain(tumor_im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,10,kernel_size=(3,3),padding=1),\n",
    "            nn.Conv2d(10,10,kernel_size=(3,3),padding=1),\n",
    "            nn.Conv2d(10,10,kernel_size=(3,3),padding=1)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
